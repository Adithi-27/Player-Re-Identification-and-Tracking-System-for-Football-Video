# -*- coding: utf-8 -*-
"""Re_identification_in_a_single_feed.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M4UJmQic4Ak-VbwNqA8iQpYP8YVgDVuY
"""

!pip install ultralytics

!pip install deep_sort_realtime

"""**Import Libraries**


"""

import cv2
import numpy as np
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
from collections import defaultdict
import matplotlib.pyplot as plt
import seaborn as sns
import os
from math import hypot
import torch
import torchvision.transforms as transforms
from torchvision.models import resnet18
from sklearn.metrics.pairwise import cosine_similarity

"""**Initialization**"""

video_path = "/content/15sec_input_720p.mp4"
model_path = "/content/best.pt"
model = YOLO(model_path)
tracker = DeepSort(max_age=30, n_init=3)

cap = cv2.VideoCapture(video_path)
width, height = int(cap.get(3)), int(cap.get(4))
fps = cap.get(cv2.CAP_PROP_FPS)
out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

# Data structures for analysis
player_tracks = defaultdict(list)
heatmap = np.zeros((height, width), dtype=np.float32)
unique_ids = set()
player_speeds = defaultdict(list)
player_embeddings = {}
passes = []
frame_idx = 0

# Appearance-based Re-ID model
device = "cuda" if torch.cuda.is_available() else "cpu"
reid_model = resnet18(pretrained=True).eval().to(device)
extract_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

def get_embedding(crop):
    tensor = extract_transform(crop).unsqueeze(0).to(device)
    with torch.no_grad():
        return reid_model(tensor).cpu().numpy().flatten()

def match_id(crop, known_embeddings, threshold=0.8):
    emb = get_embedding(crop).reshape(1, -1)
    best_id, best_score = None, 0
    for pid, ref_emb in known_embeddings.items():
        sim = cosine_similarity(emb, ref_emb.reshape(1, -1))[0][0]
        if sim > best_score and sim > threshold:
            best_id = pid
            best_score = sim
    return best_id

"""**Frame Loop**"""

if not os.path.exists("snapshots"):
    os.makedirs("snapshots")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    frame_idx += 1

    results = model(frame)[0]
    detections = []
    ball_position = None

    for r in results.boxes.data.tolist():
        x1, y1, x2, y2, score, cls = r
        cls = int(cls)
        bbox = [x1, y1, x2 - x1, y2 - y1]
        if cls == 0:  # player
            detections.append((bbox, score, 'player'))
        elif cls == 1:  # ball
            cx, cy = int((x1 + x2)/2), int((y1 + y2)/2)
            ball_position = (cx, cy)
            cv2.circle(frame, (cx, cy), 7, (0, 0, 255), -1)
            cv2.putText(frame, 'Ball', (cx + 10, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

    tracks = tracker.update_tracks(detections, frame=frame)

    for track in tracks:
        if not track.is_confirmed():
            continue

        track_id = track.track_id
        l, t, r, b = map(int, track.to_ltrb())
        cx = int((l + r) / 2)
        cy = int((t + b) / 2)

        # Re-ID embedding
        crop = frame[t:b, l:r]
        if crop.size > 0:
            emb = get_embedding(crop)
            player_embeddings[track_id] = emb

        # Track and heatmap
        unique_ids.add(track_id)
        player_tracks[track_id].append((cx, cy))
        heatmap[cy, cx] += 1

        # Speed estimation
        if len(player_tracks[track_id]) >= 2:
            x1, y1 = player_tracks[track_id][-2]
            x2, y2 = player_tracks[track_id][-1]
            dist = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
            speed = dist * fps
            player_speeds[track_id].append(speed)
            cv2.putText(frame, f'{speed:.1f}px/s', (l, b + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 100, 255), 2)

        # Pass detection
        if ball_position:
            distance = hypot(ball_position[0] - cx, ball_position[1] - cy)
            if distance < 50:
                passes.append((frame_idx, track_id))
                cv2.putText(frame, "Pass!", (cx, cy - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)

        # Draw
        cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)
        cv2.putText(frame, f'Player {track_id}', (l, t - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        # Snapshot
        if frame_idx == 100 and crop.size > 0:
            cv2.imwrite(f"snapshots/player_{track_id}_f{frame_idx}.jpg", crop)

    out.write(frame)

cap.release()
out.release()

#Analysis Plots
print(f"\n Tracking Complete: {len(unique_ids)} unique players re-identified.")

plt.figure(figsize=(14, 12), dpi=150)
sns.heatmap(heatmap, cmap='hot')
plt.title('Player Presence Heatmap')
plt.xlabel("Frame Width")
plt.ylabel("Frame Height")
plt.show()

blank = np.ones((height, width, 3), dtype=np.uint8) * 255
for track_id, positions in player_tracks.items():
    # Convert track_id to integer for color calculation
    numeric_track_id = int(track_id)
    for i in range(1, len(positions)):
        # Use the numeric_track_id for calculation
        cv2.line(blank, positions[i-1], positions[i], (0, 100 + (numeric_track_id*10) % 155, 255), 2)
    cv2.putText(blank, f"Player {track_id}", positions[-1], cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)

plt.figure(figsize=(16, 14), dpi=120)
plt.imshow(cv2.cvtColor(blank, cv2.COLOR_BGR2RGB))
plt.title("Player Movement Trajectories", fontsize=20)
plt.axis("off")
plt.tight_layout()
plt.show()

for pid, speeds in player_speeds.items():
    if speeds:
        avg_speed = np.mean(speeds)
        print(f" Player {pid} Avg Speed: {avg_speed:.2f} px/s")

print("\n Video saved as output.mp4")
print(" Heatmap and trajectories generated.")
print(f" Total unique players detected: {len(unique_ids)}")
print(f" Total passes detected: {len(passes)}")